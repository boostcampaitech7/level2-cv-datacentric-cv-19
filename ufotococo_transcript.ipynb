{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "위에것은 공백만 살리기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# -*- coding:utf-8 -*-\n",
    "from typing import Dict\n",
    "import json\n",
    "import datetime\n",
    "\n",
    "now = datetime.datetime.now()\n",
    "now = now.strftime('%Y-%m-%d %H:%M:%S')\n",
    "\n",
    "input_path = '/data/ephemeral/home/newcode2/code/data/chinese_receipt/ufo/train.json'\n",
    "output_path = '/data/ephemeral/home/coco모음집/다른것도/chinese_coco.json'\n",
    "\n",
    "info = {\n",
    "    'year': 2024,\n",
    "    'version': '1.0',\n",
    "    'description': 'OCR Competition Data',\n",
    "    'contributor': 'Naver Boostcamp',\n",
    "    'url': 'www.naver.com',\n",
    "    'date_created': now\n",
    "}\n",
    "licenses = {\n",
    "    'id': '1',\n",
    "    'name': 'For Naver Boostcamp Competition',\n",
    "    'url': None\n",
    "}\n",
    "categories = [{\n",
    "    'id': 1,\n",
    "    'name': 'word'\n",
    "}]\n",
    "\n",
    "def ufo_to_coco(file: Dict, output_path: str) -> None:\n",
    "    img_id = 1 \n",
    "    img_id_anno = 1  \n",
    "    annotation_id = 1  \n",
    "    images = []\n",
    "    annotations = []\n",
    "\n",
    "    for fname, data in file.items():\n",
    "        if img_id <= 1000:\n",
    "            image = {\n",
    "                \"id\": img_id_anno,\n",
    "                \"width\": data['img_w'],\n",
    "                \"height\": data['img_h'],\n",
    "                \"file_name\": fname,\n",
    "                \"license\": 1,\n",
    "                \"date_captured\": now\n",
    "            }\n",
    "            images.append(image)\n",
    "            for anno_id, annotation in data['words'].items():\n",
    "                # 'transcription'\\uc774 \\ube48 \\ubb38\\uc790\\uc5f4\\uc778 \\uacbd\\uc6b0\\uc5d0\\ub9cc \\uc800\\uc7a5\n",
    "                if annotation.get(\"transcription\", \"\") == \"\":\n",
    "                    min_x = min(item[0] for item in annotation['points'])\n",
    "                    min_y = min(item[1] for item in annotation['points'])\n",
    "                    max_x = max(item[0] for item in annotation['points'])\n",
    "                    max_y = max(item[1] for item in annotation['points'])\n",
    "                    width = max_x - min_x\n",
    "                    height = max_y - min_y\n",
    "                    coco_annotation = {\n",
    "                        \"id\": annotation_id,\n",
    "                        \"image_id\": img_id_anno,\n",
    "                        \"category_id\": 1,\n",
    "                        \"segmentation\": [[value for sublist in annotation['points'] for value in sublist]],\n",
    "                        \"bbox\": [min_x, min_y, width, height],\n",
    "                        \"iscrowd\": 0,\n",
    "                        \"attributes\": {\n",
    "                            \"transcription\": annotation[\"transcription\"]\n",
    "                        }\n",
    "                    }\n",
    "                    \n",
    "                    annotations.append(coco_annotation)\n",
    "                    annotation_id += 1\n",
    "            img_id_anno += 1\n",
    "        img_id += 1\n",
    "        \n",
    "    coco = {\n",
    "        'info': info,\n",
    "        'images': images,\n",
    "        'annotations': annotations,\n",
    "        'licenses': licenses,\n",
    "        'categories': categories,\n",
    "    }\n",
    "    with open(output_path, 'w') as f:\n",
    "        json.dump(coco, f, indent=4, ensure_ascii=False)\n",
    "\n",
    "with open(input_path, 'r') as f:\n",
    "    file = json.load(f)\n",
    "ufo_to_coco(file['images'], output_path)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "transcription 공백제외"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# -*- coding:utf-8 -*-\n",
    "from typing import Dict\n",
    "import json\n",
    "import datetime\n",
    "\n",
    "now = datetime.datetime.now()\n",
    "now = now.strftime('%Y-%m-%d %H:%M:%S')\n",
    "\n",
    "input_path = '/data/ephemeral/home/newcode2/code/data/vietnamese_receipt/ufo/train.json'\n",
    "output_path = '/data/ephemeral/home/coco모음집/다른것도/vietnamese_coco.json'\n",
    "\n",
    "info = {\n",
    "    'year': 2024,\n",
    "    'version': '1.0',\n",
    "    'description': 'OCR Competition Data',\n",
    "    'contributor': 'Naver Boostcamp',\n",
    "    'url': 'https://aistages-api-public-prod.s3.amazonaws.com/app/Competitions/000273/data/data.tar.gz',\n",
    "    'date_created': now\n",
    "}\n",
    "licenses = {\n",
    "    'id': '1',\n",
    "    'name': 'For Naver Boostcamp Competition',\n",
    "    'url': None\n",
    "}\n",
    "categories = [{\n",
    "    'id': 1,\n",
    "    'name': 'word'\n",
    "}]\n",
    "\n",
    "def ufo_to_coco(file: Dict, output_path: str) -> None:\n",
    "    img_id = 1 \n",
    "    img_id_anno = 1  # COCO는 1부터\n",
    "    annotation_id = 1  # COCO는 1부터\n",
    "    images = []\n",
    "    annotations = []\n",
    "\n",
    "    for fname, data in file.items():\n",
    "        if img_id <= 1000:\n",
    "            image = {\n",
    "                \"id\": img_id_anno,\n",
    "                \"width\": data['img_w'],\n",
    "                \"height\": data['img_h'],\n",
    "                \"file_name\": fname,\n",
    "                \"license\": 1,\n",
    "                \"date_captured\": now\n",
    "            }\n",
    "            images.append(image)\n",
    "            for anno_id, annotation in data['words'].items():\n",
    "                # 'transcription'이 빈 문자열이 아닐 경우에만 저장\n",
    "                if annotation.get(\"transcription\", \"\") != \"\":\n",
    "                    min_x = min(item[0] for item in annotation['points'])\n",
    "                    min_y = min(item[1] for item in annotation['points'])\n",
    "                    max_x = max(item[0] for item in annotation['points'])\n",
    "                    max_y = max(item[1] for item in annotation['points'])\n",
    "                    width = max_x - min_x\n",
    "                    height = max_y - min_y\n",
    "                    coco_annotation = {\n",
    "                        \"id\": annotation_id,\n",
    "                        \"image_id\": img_id_anno,\n",
    "                        \"category_id\": 1,\n",
    "                        \"segmentation\": [[value for sublist in annotation['points'] for value in sublist]],\n",
    "                        \"iscrowd\": 0,\n",
    "                        \"attributes\": {\n",
    "                            \"transcription\": annotation[\"transcription\"],  # 여기에 transcription을 포함\n",
    "                        }\n",
    "                    }\n",
    "                    \n",
    "                    annotations.append(coco_annotation)\n",
    "                    annotation_id += 1\n",
    "            img_id_anno += 1\n",
    "        img_id += 1\n",
    "        \n",
    "    coco = {\n",
    "        'info': info,\n",
    "        'images': images,\n",
    "        'annotations': annotations,\n",
    "        'licenses': licenses,\n",
    "        'categories': categories\n",
    "    }\n",
    "    with open(output_path, 'w') as f:\n",
    "        json.dump(coco, f, indent=4, ensure_ascii=False)\n",
    "\n",
    "with open(input_path, 'r') as f:\n",
    "    file = json.load(f)\n",
    "ufo_to_coco(file['images'], output_path)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
